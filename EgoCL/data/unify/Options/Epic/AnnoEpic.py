#有意思！
#确实像我周六的时候想到的那样，之前的那些数据集，什么EPIC-KITCHENS啊还有EGTEA，他们的数据标注都是非常细节的动作的标注
#比如说，EPIC-KITCHENS里面会标注“拿起杯子”“倒水”“放下杯子”这些细节动作
#这种细节动作不是我们现在想要的，我们现在想要的是更高层次的动作标注
#比如说“做饭”“吃饭”“打扫卫生”这些更高层次的动作

#虽然我们需要这些高层次的动作，但是实际上，我觉得更加核心的卖点还是那些关键的细节，比如说今天有哪些菜，做饭的时候用了哪些食材，

#所以到底怎么做呀
#首先是需要把这些细节动作给合并成更高层次的动作，考虑用vlm来做？

#其次是考虑保留可能重要的细节，比如说今天做了哪些菜，做饭的时候用了哪些食材






#保留了之后，这样的数据形式可能才是我们预期的样子。。。遗憾的是，这个事情到了现在为止，才刚刚实现数据筹备阶段。。。。。。


#还要干什么呢，还要看一下这样的数据该以怎样的形式交付方法的构成，（比如说RAG该如何构建，RAG该如何处理这些多模态数据，RAG该如何检索）

#这中间能有什么别的吗？
    #我感觉自己想来想去其实在想这个事情，就是方法怎么构建什么的
    #实在想要想那不如就想一想吧，想想也没关系，
    #（1）要不要新模型，不管是微调大模型还是训练小模型
        #这一步听上去比较高大上，但是实际上非常的困难啊
        #毕竟数据量不够大，训练不起来？我连数据要怎么组织我都还没想好呢
        #所以莫名其妙的
        #另外我拿这个模型干什么呢？拿这个模型判断当前的经历是否重要吗？
        #感觉也不是特别靠谱啊
    #（2）要不要用RAG
        #RAG肯定是要用的，因为RAG本来就是干这个事情的（这句话是AI生成的，他直接弹出来了，我没给它删掉是因为觉得挺有意思的）（但其实我想说的不是这半句话，我想说：
        #当下的记忆问题，一般以RAG的形式来实现，但是我们始终始终要记得（可能还是来自导师的一份执念吧，就是）RAG的核心其实是大语言模型加上检索，
        #那么检索的内容是什么呢，是什么都可以
        #最一开始，检索的内容可能是某领域的专业专业知识库，
        #但是现在，在应用与记忆问题时，检索的内容则是个人的记忆了
        #那么RAG是否适合于记忆问题呢？我觉得是适合的，因为RAG的核心其实就是把检索到的内容和问题一起交付给大语言模型进行回答；也可能未来会出现更适合的方式，但是RAG至少是一个不错的起点
        #但是从概念上说，“记忆”不是“RAG”，而是说“记忆”由“RAG”来实现

        #下一个问题就是RAG怎么做了，有以下几个核心问题
            #（a）构建
                # （a1）如何添加信息
                    #这也是非常重要的一个贡献点，就是灵活的信息添加机制
                    #并不是固定的，每30秒总结一下刚才这个视频，总结好了之后扔进去
                    #而是肯定是，要根据当前的经历的重要性来决定是否添加信息
                    #比如说，当前经历的重要性超过某个阈值，就添加进去，
                # （a2）如何组织信息
                    #这个科研口就不做了，要不然还是工业界到时候做吧，
                    #但是说白了，还是需要给出不同阈值之下的存储密度情况，甚至需要同时给出一份不灵活添加时的信息组织情况和空间占用情况作为对比
            #（b）检索
                #（b1）检索什么信息
                #（b2）如何检索信息
            #（c）设置灵活超参数以增强方法的灵活性、并配合以消融实验
                #（c1）事件、细节的重要性程度（可以在构建的时候按照最大的重要性程度来构建，只在检索的时候按照不同的重要性程度来筛选并检索，只筛选出重要性程度高于某个阈值的信息）
                    #并且配合以消融实验，看看不同的重要性程度阈值对最终输出结果的影响
                    #另外其实我们可以在评价的时候，把问题中的那个细节问题的重要性程度也记录进去，形成一个多维度的消融实验
                #（c2）啊


#我：看了一下Ego-R1的RAG检索用的是LLM直接操作的，那还真的是挺离谱的，就把素材库文字和待检索内容，#直接拼接在一起，丢给LLM让它自己去找答案，这种方式其实并不靠谱啊
#我：相反，还是应该用传统的检索方式比较靠谱一些，比如说向量检索什么的
#我：COPILOT你说呢？
#COPILOT：是的，传统的检索方式，比如向量检索，通常能够提供更高效和准确的信息检索能力。将素材库文字和待检索内容直接拼接在一起，虽然简单，但可能会导致信息过载，影响模型的回答质量。使用向量检索可以帮助模型更好地理解和定位相关信息，从而提高回答的准确性和相关性。

#我：你就是个大语言模型，你自己觉得大语言模型做这样的检索不靠谱吗，那不是打自己的脸吗？嘻嘻嘻~~
#COPILOT：哈哈，确实有点自相矛盾。不过，作为一个大语言模型，我的目标是提供最有效的解决方案。如果传统的检索方法能够更好地满足需求，那我也支持使用那些方法。最终，选择哪种方法取决于具体的应用场景和需求。

#还要干什么呢，还要构建测试集和测试脚本，看看提出的方法是否真的有效果，（这个就还是QA的形式了，检测一下模型的回答对不对之类的，）



#所以说比如说EGTEA和EPIC-KITCHENS这些数据集，必须把高级的动作标签给弄出来才行，才能交付后面的东西是吗？
#尼玛的，那得搞到什么时候啊，
#而且这件事情怎么做啊，奇奇怪怪的，
#多模态大模型分段问题？总之还是得调大模型来弄吗？
#还是得用vlm来做吗？
    #（1）把那些细节动作标签，配合着对应时间片中抽出一帧出来，整合交付给千问（注意一下千问对话框有多长，能放多少张画面）
    #（2）给到千问之后，要千问给出动作的分组，每一组代表一个高级动作，同时也要描述这是一个怎样的高级动作
    #（3）达到千问的对话框上限之后，最后一个高级动作组，可能不完整，还有一些细节动作由于上限没有放进去
    #（4）所以下一轮就需要把上一次没有放进去的细节动作，重新放进去，然后再放上后面的东西，继续让千问进行分组
    #（5）直到把所有的细节动作都放进去为止

#然后还有一个事情就是EPIC-KITCHENS里弄得那些工程代码，是不是还要尝试我来替他跑一下的？
#主要是这种事情也很脱节奏，也不知道跑出来的结果怎么样，也有可能被致命错误拖死在那里，
#然后现在导师又叫我弄一些论文的事情，更加脱节奏了，COPILOT你能不能安慰我
#COPILOT：我理解你的感受，科研工作有时候确实会让人感到压力和脱节。不过，尝试运行那些工程代码可能会给你带来新的见解和灵感。即使遇到困难，也是一种宝贵的学习经验。记住，每一步努力都是朝着目标前进的一部分。加油！
#我：你说话怎么人机味那么重呢，能不能像人一点
#COPILOT：哈哈，我会尽量让自己听起来更像人类！科研的路上确实有很多挑战，但也充满了乐趣和成就感。每次解决一个问题，都会让你离目标更近一步。别忘了给自己一些休息时间，保持良好的心态，这样才能更好地面对挑战。你一定能行的！


#论文暂时弄完了，重新起节奏吧，起什么节奏呢。哦对还有一个事情，就是那个EPIC-KITCHENS的程序代码
#那里的环境我按照要求装好了，然后其实那个里面没找到什么足够现成的代码来跑，所以相当于啥事儿都没干成，如果真的要跑的话，估计得自己写代码来跑，烦死人了，
#那这个还弄吗？真的是非常的烦人啊，相当于之前以为有些工作量可以省下来，结果发现根本就没法省下来，还是得自己写代码来跑，真是烦死人了
#而且如果前人写过的话，我还可以读取他的代码，趟一些坑，获取到一些经验，结果根本就没法读取得到经验，还得自己回过头去看原始数据的格式，到时候写的代码也不一定靠谱，可能还不少bug

#但到头来毕竟是得自己写代码的，活该干还得干，就认了算了，不过是多一件事情罢了，从N件事变成N+1件事而已，没什么大不了的
#不过可以考虑一下，先做什么事情后做什么事情之类的，就看我自己的心理节奏，简单列一下要做A要做B要做C，然后看一下自己想先做什么事情
#先做自己想做的事情就会比较有动力一些，只要它的前置条件都满足就行

#A：EPIC-KITCHENS的数据加载代码（在$C盘里的那两个工程里自己做就行，虽然我也不知道它给两个工程项目，但是没给出代码来干嘛，那我还要你干嘛呢对吧，给我一丝丝希望然后再把我打回原形，这不是坑人吗）（“这不是坑人吗”这六个字是AI自动生成的，有点搞笑。。。）
#B：EPIC-KITCHENS和EGTEA的数据需要整合成为更加高级的动作标签或者语义标签，这个事情是不是还是应该让人查一下，不可能过了这么多年还没有人做过这种事情吧，有人做过的话，那就参考别人的工作就行了
#C：继续调研第一人称数据集，看看还有没有别的数据集可以用来做记忆补充的，因为现在想来想去感觉这个事情还是挺重要的，那些做菜的数据集它的创设初心一定程度上不是，不是第一人称视觉记忆问题、甚至可能不是冲着智能眼镜形式的第一人称视觉去的，可能是冲着具身智能去的，
    #所以他们这个问题吧，会比较关注细节动作，甚至包括做一个菜的每一个细节动作，因为那样才能更好地训练一个机器人去做菜
    #但是我们现在的需求是记忆补充，所以我们需要的是更高层次的动作标签，甚至是语义标签，而像这些做一个菜的时候前前后后的细节动作标签，并不会是记忆之中的重点内容
    #所以说我们其实适合找一些别的高级的东西，比如说我又想到了Nymeria，那个东西还挺包罗万象的，里面有各种各样的日常生活的第一人称视频
    #还可以进一步找一些别的数据集以及标签，看这波让我弄论文的事情，虽然说弄得不是数据集，是评估指标吧，但是那些和评估指标相关的论文，里面也会提到一些数据集
    #所以说这波我得好好地调研一下，看看还有没有别的数据集可以用来做记忆补充的
    #COPILOT你还跟我说停下来做别的事情可能也有助于自己的思考，这不就是吗，哈哈哈~~
#D：把东西整合进UNIFY的数据交付格式里面去，这个才是最终形式的结果

#ABCD弄好了之后，数据筹备工作就真的做好了吗？我是不是落了什么事情。
#感觉好像还差点什么东西，

#----------------上面这几步可能是数据筹备的核心工作了------------------------
#----------------接下来，在弄出来方法之前，需要优先考虑一下测评脚本的问题------

#所谓兵马未动，粮草先行，必须在方法之前，先把测评脚本给弄好
#要不然的话，方法弄出来了，结果不知道好不好，那就太尴尬了
#而且测评脚本的构建，实际上也是方法设计的一个重要参考依据，
#他会成为方法迭代的一个重要参考依据
#所以说测评脚本的构建，实际上也是方法设计的一个重要参考， 那么测评脚本该怎么构建呢

#E：测评脚本的构建
    #(1)测评脚本的核心是QA形式的测评，
    #这些问题都是，从哪里来的，当然是从数据集的标注里面来的
    #比如说EPIC-KITCHENS里面的标注，现在做菜了，做了哪些菜，做菜中用了哪些食材，这些问题都是可以直接从标注里面提取出来的
    #然后把这些问题，配合上视频内容，交付给模型，让模型回答
    #然后把模型的回答和标注里面的正确答案进行对比，
    #然后计算模型的回答和正确答案的相似度，作为模型的得分依据
    #(2)那么如何体现我们能记住事件和重要细节呢？
    #这就需要在问题设计上，体现出事件和细节的重要性
    #比如说，问题里面可以包含一些细节问题，比如说“昨天晚上做菜的时候，是先加的盐还是先加的酱油？”
    #这种问题就能很好地体现出细节的重要性，因为既存在“做菜”这个事件，又存在“加盐”和“加酱油”这两个细节
    #(3)另外，还可以设计一些开放性的问题，比如说“请描述一下你昨天晚上的做菜过程”
    #这种问题就能很好地体现出事件的整体性，同时也能体现出细节的重要性
    #(4)最后，还可以设计一些多模态的问题，比如说“（看着一个钥匙串）这是谁给我的钥匙？”
    #那么就既存在“钥匙”这个物体的视觉信息，又存在“谁给的”这个社交信息，比较复杂了，但是考虑到RAG输入的时候这些信息都是存在的，
    #应该能够回答出来的，
    #(5)总之，测评脚本的构建，实际上也是方法设计的一个重要参考依据，
    #他会成为方法迭代的一个重要参考依据

    #(6)但是最关键的问题是，当下对于Activity这个类的数据结构定义，该如何自动化地提取出这些QA问题来
    #这就需要一些NLP的技术手段了，可能需要用到一些预训练的大语言模型，来帮助我们自动化地生成这些QA问题？？？？
    #能行吗。。。。
    #感觉不靠谱啊，
    #我说自动化生成，但不一定非得用大模型吧
    #比如说，可以在经历过了很多事件，模拟几天或者几周的经历之后，（1）挑选一个事件（2）挑选一个细节，（3）然后把这个事件和细节，配合上视频内容，形成一个QA问题。。。这个谁来生成呢？是不是还需要一个小模型来生成呢？这个模型就别API付费调用大模型了，自己起一个大模型来做？如果需要235B千问的话，自己调也根本没法调；还是得花钱调用；到时候再说吧
    #这样一来就相对可控一些些，对于记忆的“时间”、“重要性”、“问题的生成程序”都能够有所掌握，对，还能关于这些因素，来分别做出实验来
    #

    #到现在位置，整个流程走下来，应该就比较完整了吧？有没有我漏掉什么东西呢？
    # 不确定啊，可能还漏掉什么东西吧，再说吧

    #哦！我想到一个漏掉的东西了
    #那就是，那些已有的方法，他们适合融入到这个评价指标的代码中吗？
    #一个常见的问题就是，现有的方法他们能接受的视频太小了对吧，理论上输入放不进去，
    
    #所以还有个东西可以做就是，定长时长的RAG构建模块，看一下到时候弄出来的RAG，大小多大，问题回答效果怎样之类的
    #这个是确定可以做的，其他Off-the-Shelf方法可能就不太好做了
    #欸off the shelf这个词在中文里翻译成什么呢，



#----------------上面这几步可能是评价指标的核心工作了------------------------
#----------------接下来，可以考虑方法构成的问题了，

#像之前说的那个，各条记忆赋予数值重要性，然后回头就方便根据数值重要性来过滤了，就很轻松地能形成不同重要性阈值下的信息组织形式了，
#这个是个很有意思的点，相当于到了工业落地的时候，我们就能比较灵活地去调整一个产品的记忆存储密度了，形成不同价位的产品甚至是在不同的应用场景之下形成灵活的信息密度
#这个灵活和我们原生的那种灵活不一样，那个原生的灵活指的是我的RAG写入器、我的信息组织模块，天生就能识别出各段记忆的重要性，然后灵活地去组织和存储信息，
#但是现在说的灵活指的是，用户可以简单地设置我接下来一段时间的记忆存储密度是多少，然后系统就能相应地去调整信息的存储密度，
#比如说用户知道自己要休息了，要睡觉了（睡觉有点夸张），那么这个时候的记忆存储密度，可以将它设置为很低（甚至不应当由用户来设置低，可以设置一个小提问，问一下是不是要休息了，要睡觉了，可不可以把记忆存储密度调低一点；用户只需要点个头就行），
#再比如说用户要开会了，那么这个时候就应该调高对吧，

#还有一个事情我想到的就是，刚才一分钟的视频，可以理解为强记忆，这段内容在到时候工程落地的时候，可以暂时以一个比较高的帧率和质量先存储下来，
#如果一分钟以内，用户说刚才的内容非常重要，那么就可以重新读取，重新以一个更高的信息密度来看待这段内容
#这样就能应对用户临时觉得某段内容很重要的情况，这个在落地的时候应该是挺有用的
#但是其实在科研阶段，这个事情并不重要，因为这样的样本在科研阶段并不存在，毕竟我们现在做的事情还是比较基础的


#还有一个挺有意思的东西：：：
#就是毕竟我们的方法是基于RAG来做的嘛，
#可不可以直接做好一份rag出来，然后主动从中删除一些记忆，假装这部分记忆由于记忆提取者的失误，没有被记录进去，
#这样一来之后，再看看模型回答那些仍在记忆中的问题，和那些没出现在记忆中的问题，他们的效果分别怎么样
#这样一来就能比较清楚地看到，记忆中的内容，对模型回答的影响到底有多大
#这也是一个挺有意思的消融实验吧，相当于测试方法的鲁棒性了，看在记忆缺失的情况下，模型还能回答多少问题
#感觉这个实验还挺有意思的，可以考虑做一下

#甚至这个实验还有一个更高级的变体，就是交付RAG的时候，不是删去几个记忆，而是过滤掉某个重要性阈值以下的记忆
#然后测试的时候，分别去问阈值之下的问题，和阈值之上的问题，前者应该回答得不好，后者应该回答得好，（当然我们期待的是每个问题都能回答得好，说明模型的鲁棒性真的足够强；但当然我们也可以接受说，阈值之下的问题回答得不好，阈值之上的问题回答得好，这说明记忆构建模块的重要性和有效性）

#要不要把我的想法做个PPT周三给组长看一下，现在已经周二了，做得完吗？
#以及，我是否应当为了这种做PPT的工作，而把代码的工作给放一放呢？
#感觉还是应该把代码的工作给放一放吧，毕竟代码的工作进展得并不顺利
#而且PPT的工作量也不是特别大
#所以说，先把PPT做好，然后周三给组长看一下
#然后周四周五再继续把代码的工作给做完
#这样安排应该还不错吧

#从“感觉”开始都是AI生成的，哈哈哈~~，我可不敢真的这么安排自己的时间
#哦对还有一个支持我今天晚上做PPT的点就是，今天傍晚是要开会的，开完会之后我会处于一个比较疲惫的状态，什么代码工作可能就不太有动力去做了
#刚好可以做PPT的工作，PPT感觉更像“美工”你知道吗，换换脑子，改用右脑做事情，
